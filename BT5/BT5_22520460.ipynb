{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Import Library"
      ],
      "metadata": {
        "id": "pRAf0xNClzAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YczE55EXiYx9",
        "outputId": "7be05be4-b53d-44d1-de9e-67a183b395f7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhSyhfEy4XSD"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gymnasium as gym\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Initialize with FrozenLake-v1"
      ],
      "metadata": {
        "id": "8mIoteTQl7Fk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHf1dAVKAcZm"
      },
      "source": [
        "env = gym.make('FrozenLake-v1', render_mode=\"ansi\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-6usoQHAmqh",
        "outputId": "e87ab1d7-8607-435c-f39e-239860f4243e"
      },
      "source": [
        "env.P[0][3] # Transition model"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.P to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.P` for environment variables or `env.get_wrapper_attr('P')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.3333333333333333, 1, 0.0, False),\n",
              " (0.3333333333333333, 0, 0.0, False),\n",
              " (0.3333333333333333, 0, 0.0, False)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh7Su0h0AqQz",
        "outputId": "d475450a-6d0e-4b99-9dd8-624eaed51c33"
      },
      "source": [
        "env.observation_space.n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ68w5bpBScC",
        "outputId": "a6c69e83-b503-4df6-dcb7-67e43965bb07"
      },
      "source": [
        "env.action_space.n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWLnvY7VBvIZ"
      },
      "source": [
        "def play(env, policy, render=False):\n",
        "    state, _ = env.reset()\n",
        "    total_reward = 0\n",
        "    steps = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = policy[state]\n",
        "        next_state, reward, done, info, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "        steps += 1\n",
        "        if render:\n",
        "            print(env.render())\n",
        "            time.sleep(0.5)\n",
        "            if not done:\n",
        "                display.clear_output(wait=True)\n",
        "        state = next_state\n",
        "\n",
        "    return (total_reward, steps)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy_0 = np.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "play(env, policy_0, True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ1CJNPhDGPA",
        "outputId": "0f826557-0b2f-4095-fdff-933b9375ea07"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "\u001b[41mH\u001b[0mFFG\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdyjjtGZC9NX",
        "outputId": "39a85eac-31e6-4d5c-e764-8765ef369865"
      },
      "source": [
        "policy_1 = np.asarray([0, 1, 1, 3, 1, 0, 2, 0, 1, 1, 2, 2, 3, 3, 1, 0])\n",
        "play(env, policy_1, True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "\u001b[41mH\u001b[0mFFG\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt0VhyMuDasc",
        "outputId": "dcbf2a2f-12eb-4b51-e274-1d269d5e81bb"
      },
      "source": [
        "policy_2 = np.array([1, 1, 1, 3, 0, 1, 2, 3, 1, 1, 2, 3, 2, 2, 1, 3])\n",
        "play(env, policy_2, True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "\u001b[41mH\u001b[0mFFG\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp6qhRFJDxWR",
        "outputId": "7d5cf69f-c0cf-49de-fd3e-c60e51454dbb"
      },
      "source": [
        "policy_3 = np.array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0])\n",
        "play(env, policy_3, True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 56)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU8Q1qMxD6Po"
      },
      "source": [
        "def play_multiple_times(env, policy, max_episodes):\n",
        "    success = 0\n",
        "    list_of_steps = []\n",
        "    for i in range(max_episodes):\n",
        "        total_reward, steps = play(env, policy)\n",
        "\n",
        "        if total_reward > 0:\n",
        "            success += 1\n",
        "            list_of_steps.append(steps)\n",
        "\n",
        "    print(f'Number of successes: {success}/{max_episodes}')\n",
        "    print(f'Average number of steps: {np.mean(list_of_steps)}')\n",
        "    return success, np.mean(list_of_steps)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G427z17PEmjQ",
        "outputId": "44c32521-59d4-44ef-c104-5496c02c29ef"
      },
      "source": [
        "policy_0 = np.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "play_multiple_times(env, policy_0, 1000)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 0/1000\n",
            "Average number of steps: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, nan)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1bkhaFdDmj_",
        "outputId": "cea4ba8c-ec0d-4a3d-9f00-e6c7c3b892fc"
      },
      "source": [
        "policy_1 = np.asarray([0, 1, 1, 3, 1, 0, 2, 0, 1, 1, 2, 2, 3, 3, 1, 0])\n",
        "play_multiple_times(env, policy_1, 1000)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 53/1000\n",
            "Average number of steps: 11.150943396226415\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53, 11.150943396226415)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZYhsb_VEtuR",
        "outputId": "17a6e9c7-22ae-4308-ecb0-5464e37e88c3"
      },
      "source": [
        "policy_2 = np.array([1, 1, 1, 3, 0, 1, 2, 3, 1, 1, 2, 3, 2, 2, 1, 3])\n",
        "play_multiple_times(env, policy_2, 1000)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 101/1000\n",
            "Average number of steps: 16.722772277227723\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101, 16.722772277227723)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvvHdMesEzTH",
        "outputId": "85a52f4f-fd97-4877-f79d-43e48a3bca32"
      },
      "source": [
        "policy_3 = np.array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0])\n",
        "play_multiple_times(env, policy_3, 1000)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 785/1000\n",
            "Average number of steps: 43.44203821656051\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(785, 43.44203821656051)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSomNpxJE5lP"
      },
      "source": [
        "def policy_evaluation(env, policy, max_iters=500, gamma=0.9, verbose=True):\n",
        "    # Initialize the values of all states to be 0\n",
        "    v_values = np.zeros(env.observation_space.n)\n",
        "\n",
        "    for i in range(max_iters):\n",
        "        prev_v_values = np.copy(v_values)\n",
        "\n",
        "        # Update the value of each state\n",
        "        for state in range(env.observation_space.n):\n",
        "            action = policy[state]\n",
        "\n",
        "            # Compute the q-value of the action\n",
        "            q_value = 0\n",
        "            for prob, next_state, reward, done in env.P[state][action]:\n",
        "                q_value += prob * (reward + gamma * prev_v_values[next_state])\n",
        "\n",
        "            v_values[state] = q_value # update v-value\n",
        "\n",
        "        # Check convergence\n",
        "        if np.all(np.isclose(v_values, prev_v_values)):\n",
        "          if verbose:\n",
        "            print(f'Converged at {i}-th iteration.')\n",
        "          break\n",
        "\n",
        "    return v_values"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7IhqEOgGkQX",
        "outputId": "44c1fefd-83f5-44bb-ff16-6a0ea9830a03"
      },
      "source": [
        "policy_0 = np.asarray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "v_values_0 = policy_evaluation(env, policy_0)\n",
        "print(v_values_0)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 0-th iteration.\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMjJKI3GGrsN",
        "outputId": "d6cd9460-b23b-45a8-8805-2969432042e0"
      },
      "source": [
        "policy_1 = np.asarray([0, 1, 1, 3, 1, 0, 2, 0, 1, 1, 2, 2, 3, 3, 1, 0])\n",
        "v_values_1 = policy_evaluation(env, policy_1)\n",
        "print(v_values_1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 48-th iteration.\n",
            "[0.01904157 0.01519815 0.03161906 0.02371389 0.02538879 0.\n",
            " 0.06648515 0.         0.05924054 0.13822794 0.18999823 0.\n",
            " 0.         0.21152109 0.56684236 0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-26M77nEfcV",
        "outputId": "ae65294d-0658-442d-f18b-5b3b20ea4090"
      },
      "source": [
        "np.all(v_values_1 >= v_values_0)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l49O1N8QG0S2",
        "outputId": "57a7e0d9-1fd0-4986-966d-3cd951f3aaaa"
      },
      "source": [
        "policy_2 = np.array([1, 1, 1, 3, 0, 1, 2, 3, 1, 1, 2, 3, 2, 2, 1, 3])\n",
        "v_values_2 = policy_evaluation(env, policy_2)\n",
        "print(v_values_2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 53-th iteration.\n",
            "[0.02889625 0.01951972 0.03616977 0.0271268  0.04790519 0.\n",
            " 0.07391985 0.         0.08288277 0.19339319 0.21022995 0.\n",
            " 0.         0.35153135 0.62684674 0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22pRvreGE3Yt",
        "outputId": "1f9f89ca-ab3b-4bb0-c4b3-5aa284b4fa54"
      },
      "source": [
        "np.all(v_values_2 >= v_values_1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTYYFq6BEXDd",
        "outputId": "4531f5d3-c605-4a47-f008-11fd7cc7be1b"
      },
      "source": [
        "policy_3 = np.array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0])\n",
        "v_values_3 = policy_evaluation(env, policy_3)\n",
        "print(v_values_3)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 80-th iteration.\n",
            "[0.06888666 0.06141097 0.07440714 0.05580443 0.09185068 0.\n",
            " 0.11220679 0.         0.14543323 0.24749485 0.29961611 0.\n",
            " 0.         0.37993438 0.63901935 0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcEfU3NYE7xN",
        "outputId": "8377d007-29fd-429d-94fe-93913c95a4c4"
      },
      "source": [
        "np.all(v_values_3 >= v_values_2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh4akjMSHJBF"
      },
      "source": [
        "def value_iteration(env, max_iters=500, gamma=0.9, verbose=True):\n",
        "    # initialize\n",
        "    v_values = np.zeros(env.observation_space.n)\n",
        "    temp = 0\n",
        "    for i in range(max_iters):\n",
        "        prev_v_values = np.copy(v_values)\n",
        "\n",
        "        # update the v-value for each state\n",
        "        for state in range(env.observation_space.n):\n",
        "            q_values = []\n",
        "\n",
        "            # compute the q-value for each action that we can perform at the state\n",
        "            for action in range(env.action_space.n):\n",
        "                q_value = 0\n",
        "                # loop through each possible outcome\n",
        "                for prob, next_state, reward, done in env.P[state][action]:\n",
        "                    q_value += prob * (reward + gamma * prev_v_values[next_state])\n",
        "\n",
        "                q_values.append(q_value)\n",
        "\n",
        "            # select the max q-values\n",
        "            best_action = np.argmax(q_values)\n",
        "            v_values[state] = q_values[best_action]\n",
        "\n",
        "        # check convergence\n",
        "        if np.all(np.isclose(v_values, prev_v_values)):\n",
        "          if verbose:\n",
        "            print(f'Converged at {i}-th iteration.')\n",
        "            temp = i\n",
        "          break\n",
        "\n",
        "    return v_values, temp"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8xAljw7VuMP",
        "outputId": "819975da-a106-4fc1-a56c-7b841575d1f3"
      },
      "source": [
        "optimal_v_values, value_iter = value_iteration(env, max_iters=500, gamma=0.9)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 79-th iteration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7g9VA3lV2WW",
        "outputId": "5220e7fa-d38c-4ae2-bc0b-02bc6b17160e"
      },
      "source": [
        "optimal_v_values"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.06888615, 0.06141054, 0.07440682, 0.05580409, 0.09185022,\n",
              "       0.        , 0.11220663, 0.        , 0.14543286, 0.2474946 ,\n",
              "       0.29961593, 0.        , 0.        , 0.3799342 , 0.63901926,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb0an7gaV39e"
      },
      "source": [
        "def policy_extraction(env, v_values, gamma=0.9):\n",
        "    # initialize\n",
        "    policy = np.zeros(env.observation_space.n, dtype=np.int32)\n",
        "\n",
        "    # loop through each state in the environment\n",
        "    for state in range(env.observation_space.n):\n",
        "        q_values = []\n",
        "        # loop through each action\n",
        "        for action in range(env.action_space.n):\n",
        "            q_value = 0\n",
        "            # loop each possible outcome\n",
        "            for prob, next_state, reward, done in env.P[state][action]:\n",
        "                q_value += prob * (reward + gamma * v_values[next_state])\n",
        "\n",
        "            q_values.append(q_value)\n",
        "\n",
        "        # select the best action\n",
        "        best_action = np.argmax(q_values)\n",
        "        policy[state] = best_action\n",
        "\n",
        "    return policy"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TGCF4G7XErH"
      },
      "source": [
        "optimal_policy = policy_extraction(env, optimal_v_values, gamma=0.9)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_policy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkHYtfm4qikV",
        "outputId": "1a51f09f-afbe-4291-e571-6e0dfacf7728"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "play(env, optimal_policy, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ww12Uh5qCUb",
        "outputId": "cc902bb8-c633-4054-9f4b-27e06948e91b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-m4ZqWZXKqG",
        "outputId": "7d004709-2a11-4438-f851-69aef58f21db"
      },
      "source": [
        "play_multiple_times(env, optimal_policy, 1000)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 788/1000\n",
            "Average number of steps: 42.55964467005076\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(788, 42.55964467005076)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_iteration(env, max_iters=500, gamma=0.9, verbose=True):\n",
        "    policy = np.zeros(env.observation_space.n, dtype=np.int32)\n",
        "    temp = 0\n",
        "    for i in range(max_iters):\n",
        "        v_values = policy_evaluation(env, policy, 500, 0.9, False)\n",
        "        new_policy = policy_extraction(env, v_values, 0.9)\n",
        "        if np.array_equal(new_policy, policy):\n",
        "          if verbose:\n",
        "            print(f'Converged at {i}-th iteration.')\n",
        "            temp = i\n",
        "          break\n",
        "        policy = new_policy\n",
        "\n",
        "    return policy, temp\n"
      ],
      "metadata": {
        "id": "XiPGMpRYECua"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_multiple_times(env, policy_iteration(env, 500, 0.9)[0], 1000)"
      ],
      "metadata": {
        "id": "8-3xyN7LXklM",
        "outputId": "7664114a-e055-4a16-b483-f278ccc47d8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged at 5-th iteration.\n",
            "Number of successes: 779/1000\n",
            "Average number of steps: 41.397946084724005\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(779, 41.397946084724005)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Experiment\n"
      ],
      "metadata": {
        "id": "sMWU12hrlUw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_ITERS = 2000\n",
        "MAX_EPISODES = 10000\n",
        "GAMMA = 0.9"
      ],
      "metadata": {
        "id": "rb77ckd4vz8s"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "statistics = []"
      ],
      "metadata": {
        "id": "6NmZfrVAy58W"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FrozenLake-v1"
      ],
      "metadata": {
        "id": "8_fr9CQIu3ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake-v1')"
      ],
      "metadata": {
        "id": "e0j2Q4VUvv4_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vi_iter_avg = 0\n",
        "pi_iter_avg = 0\n",
        "\n",
        "vi_rate_avg = 0\n",
        "pi_rate_avg = 0\n",
        "\n",
        "vi_step_avg = 0\n",
        "pi_step_avg = 0\n",
        "\n",
        "vi_time_avg = 0\n",
        "pi_time_avg = 0\n",
        "\n",
        "vi_find_optimal_avg = 0\n",
        "pi_find_optimal_avg = 0\n",
        "\n",
        "for i in range(0, 3):\n",
        "    print('Iter ', i + 1)\n",
        "    start_vi = time.time()\n",
        "    vi_value,vi_iter = value_iteration(env, MAX_ITERS, GAMMA)\n",
        "    vi_time = time.time() - start_vi\n",
        "    policy_from_value = policy_extraction(env, vi_value, GAMMA)\n",
        "    start_vi_avg = time.time()\n",
        "    vi_successes, avg_vi_steps = play_multiple_times(env, policy_from_value, MAX_EPISODES)\n",
        "    vi_avg = time.time() - start_vi_avg\n",
        "    start_pi = time.time()\n",
        "    pi, pi_iter = policy_iteration(env, MAX_ITERS, gamma=GAMMA)\n",
        "    pi_time = time.time() - start_pi\n",
        "    start_pi_avg = time.time()\n",
        "    pi_successes, avg_pi_steps = play_multiple_times(env, pi, MAX_EPISODES)\n",
        "    pi_avg = time.time() - start_pi_avg\n",
        "    print()\n",
        "    print(f'Number of successes of Value Iteration in FrozenLake-v1 : {vi_successes}/{MAX_EPISODES},  Time find the optimal policy : {vi_time}s')\n",
        "    print(f'Number of successes of Policy Iteration in FrozenLake-v1 : {pi_successes}/{MAX_EPISODES}, Time find the optimal policy : {pi_time}s')\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print()\n",
        "    vi_iter_avg += vi_iter/3\n",
        "    pi_iter_avg += pi_iter/3\n",
        "\n",
        "    vi_rate_avg += float(vi_successes)/MAX_EPISODES/3\n",
        "    pi_rate_avg += float(pi_successes)/MAX_EPISODES/3\n",
        "\n",
        "    vi_step_avg += avg_vi_steps/3\n",
        "    pi_step_avg += avg_pi_steps/3\n",
        "\n",
        "    vi_time_avg += vi_avg/MAX_EPISODES/3\n",
        "    pi_time_avg += pi_avg/MAX_EPISODES/3\n",
        "\n",
        "    vi_find_optimal_avg += vi_time/3\n",
        "    pi_find_optimal_avg += pi_time/3\n",
        "\n",
        "statistics.append(['FrozenLake-v1', vi_iter_avg, pi_iter_avg, vi_rate_avg, pi_rate_avg, vi_step_avg, pi_step_avg, vi_time_avg, pi_time_avg, vi_find_optimal_avg, pi_find_optimal_avg])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJMS320W-j58",
        "outputId": "6125f030-94eb-424f-88af-9591c5f388f9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter  1\n",
            "Converged at 79-th iteration.\n",
            "Number of successes: 7810/10000\n",
            "Average number of steps: 43.78911651728553\n",
            "Converged at 5-th iteration.\n",
            "Number of successes: 7763/10000\n",
            "Average number of steps: 42.920133968826484\n",
            "\n",
            "Number of successes of Value Iteration in FrozenLake-v1 : 7810/10000,  Time find the optimal policy : 0.10305333137512207s\n",
            "Number of successes of Policy Iteration in FrozenLake-v1 : 7763/10000, Time find the optimal policy : 0.15805315971374512s\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Iter  2\n",
            "Converged at 79-th iteration.\n",
            "Number of successes: 7821/10000\n",
            "Average number of steps: 43.02314282061118\n",
            "Converged at 5-th iteration.\n",
            "Number of successes: 7796/10000\n",
            "Average number of steps: 43.78373524884556\n",
            "\n",
            "Number of successes of Value Iteration in FrozenLake-v1 : 7821/10000,  Time find the optimal policy : 0.06744980812072754s\n",
            "Number of successes of Policy Iteration in FrozenLake-v1 : 7796/10000, Time find the optimal policy : 0.10482621192932129s\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Iter  3\n",
            "Converged at 79-th iteration.\n",
            "Number of successes: 7810/10000\n",
            "Average number of steps: 43.97836107554417\n",
            "Converged at 5-th iteration.\n",
            "Number of successes: 7826/10000\n",
            "Average number of steps: 43.62752363915155\n",
            "\n",
            "Number of successes of Value Iteration in FrozenLake-v1 : 7810/10000,  Time find the optimal policy : 0.127427339553833s\n",
            "Number of successes of Policy Iteration in FrozenLake-v1 : 7826/10000, Time find the optimal policy : 0.08964037895202637s\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FrozenLake8x8-v1"
      ],
      "metadata": {
        "id": "lMvsBBrqu7B6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake8x8-v1')"
      ],
      "metadata": {
        "id": "Ol5ncfwckdbf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vi_iter_avg = 0\n",
        "pi_iter_avg = 0\n",
        "\n",
        "vi_rate_avg = 0\n",
        "pi_rate_avg = 0\n",
        "\n",
        "vi_step_avg = 0\n",
        "pi_step_avg = 0\n",
        "\n",
        "vi_time_avg = 0\n",
        "pi_time_avg = 0\n",
        "\n",
        "vi_find_optimal_avg = 0\n",
        "pi_find_optimal_avg = 0\n",
        "\n",
        "for i in range(0, 3):\n",
        "    print('Iter ', i + 1)\n",
        "    start_vi = time.time()\n",
        "    vi_value,vi_iter = value_iteration(env, MAX_ITERS, GAMMA)\n",
        "    vi_time = time.time() - start_vi\n",
        "    policy_from_value = policy_extraction(env, vi_value, GAMMA)\n",
        "    start_vi_avg = time.time()\n",
        "    vi_successes, avg_vi_steps = play_multiple_times(env, policy_from_value, MAX_EPISODES)\n",
        "    vi_avg = time.time() - start_vi_avg\n",
        "    start_pi = time.time()\n",
        "    pi, pi_iter = policy_iteration(env, MAX_ITERS, gamma=GAMMA)\n",
        "    pi_time = time.time() - start_pi\n",
        "    start_pi_avg = time.time()\n",
        "    pi_successes, avg_pi_steps = play_multiple_times(env, pi, MAX_EPISODES)\n",
        "    pi_avg = time.time() - start_pi_avg\n",
        "    print()\n",
        "    print(f'Number of successes of Value Iteration in FrozenLake8x8-v1 : {vi_successes}/{MAX_EPISODES},  Time find the optimal policy : {vi_time}s')\n",
        "    print(f'Number of successes of Policy Iteration in FrozenLake8x8-v1 : {pi_successes}/{MAX_EPISODES}, Time find the optimal policy : {pi_time}s')\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print()\n",
        "    vi_iter_avg += vi_iter/3\n",
        "    pi_iter_avg += pi_iter/3\n",
        "\n",
        "    vi_rate_avg += float(vi_successes)/MAX_EPISODES/3\n",
        "    pi_rate_avg += float(pi_successes)/MAX_EPISODES/3\n",
        "\n",
        "    vi_step_avg += avg_vi_steps/3\n",
        "    pi_step_avg += avg_pi_steps/3\n",
        "\n",
        "    vi_time_avg += vi_avg/MAX_EPISODES/3\n",
        "    pi_time_avg += pi_avg/MAX_EPISODES/3\n",
        "\n",
        "    vi_find_optimal_avg += vi_time/3\n",
        "    pi_find_optimal_avg += pi_time/3\n",
        "\n",
        "statistics.append(['FrozenLake8x8-v1', vi_iter_avg, pi_iter_avg, vi_rate_avg, pi_rate_avg, vi_step_avg, pi_step_avg, vi_time_avg, pi_time_avg, vi_find_optimal_avg, pi_find_optimal_avg])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpFLdGpDya3Q",
        "outputId": "40c95f47-20a8-4d28-f36b-2842659c10b8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter  1\n",
            "Converged at 117-th iteration.\n",
            "Number of successes: 7520/10000\n",
            "Average number of steps: 74.48404255319149\n",
            "Converged at 9-th iteration.\n",
            "Number of successes: 7573/10000\n",
            "Average number of steps: 74.69694968968705\n",
            "\n",
            "Number of successes of Value Iteration in FrozenLake8x8-v1 : 7520/10000,  Time find the optimal policy : 0.6756384372711182s\n",
            "Number of successes of Policy Iteration in FrozenLake8x8-v1 : 7573/10000, Time find the optimal policy : 0.9585039615631104s\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Iter  2\n",
            "Converged at 117-th iteration.\n",
            "Number of successes: 7533/10000\n",
            "Average number of steps: 74.54042214257268\n",
            "Converged at 9-th iteration.\n",
            "Number of successes: 7422/10000\n",
            "Average number of steps: 74.79884128267314\n",
            "\n",
            "Number of successes of Value Iteration in FrozenLake8x8-v1 : 7533/10000,  Time find the optimal policy : 0.7504284381866455s\n",
            "Number of successes of Policy Iteration in FrozenLake8x8-v1 : 7422/10000, Time find the optimal policy : 0.98189377784729s\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Iter  3\n",
            "Converged at 117-th iteration.\n",
            "Number of successes: 7482/10000\n",
            "Average number of steps: 74.52405773857258\n",
            "Converged at 9-th iteration.\n",
            "Number of successes: 7481/10000\n",
            "Average number of steps: 75.33177382702847\n",
            "\n",
            "Number of successes of Value Iteration in FrozenLake8x8-v1 : 7482/10000,  Time find the optimal policy : 0.803490400314331s\n",
            "Number of successes of Policy Iteration in FrozenLake8x8-v1 : 7481/10000, Time find the optimal policy : 1.3026490211486816s\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taxi-v3"
      ],
      "metadata": {
        "id": "9bMakFn3vf24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('Taxi-v3')"
      ],
      "metadata": {
        "id": "Co4oskxQvizy"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vi_iter_avg = 0\n",
        "pi_iter_avg = 0\n",
        "\n",
        "vi_rate_avg = 0\n",
        "pi_rate_avg = 0\n",
        "\n",
        "vi_step_avg = 0\n",
        "pi_step_avg = 0\n",
        "\n",
        "vi_time_avg = 0\n",
        "pi_time_avg = 0\n",
        "\n",
        "vi_find_optimal_avg = 0\n",
        "pi_find_optimal_avg = 0\n",
        "\n",
        "for i in range(0, 3):\n",
        "    print('Iter ', i + 1)\n",
        "    start_vi = time.time()\n",
        "    vi_value,vi_iter = value_iteration(env, MAX_ITERS, GAMMA)\n",
        "    vi_time = time.time() - start_vi\n",
        "    policy_from_value = policy_extraction(env, vi_value, GAMMA)\n",
        "    start_vi_avg = time.time()\n",
        "    vi_successes, avg_vi_steps = play_multiple_times(env, policy_from_value, MAX_EPISODES)\n",
        "    vi_avg = time.time() - start_vi_avg\n",
        "    start_pi = time.time()\n",
        "    pi, pi_iter = policy_iteration(env, MAX_ITERS, gamma=GAMMA)\n",
        "    pi_time = time.time() - start_pi\n",
        "    start_pi_avg = time.time()\n",
        "    pi_successes, avg_pi_steps = play_multiple_times(env, pi, MAX_EPISODES)\n",
        "    pi_avg = time.time() - start_pi_avg\n",
        "    print()\n",
        "    print(f'Number of successes of Value Iteration in Taxi-v3 : {vi_successes}/{MAX_EPISODES},  Time find the optimal policy : {vi_time}s')\n",
        "    print(f'Number of successes of Policy Iteration in Taxi-v3 : {pi_successes}/{MAX_EPISODES}, Time find the optimal policy : {pi_time}s')\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print()\n",
        "    vi_iter_avg += vi_iter/3\n",
        "    pi_iter_avg += pi_iter/3\n",
        "\n",
        "    vi_rate_avg += float(vi_successes)/MAX_EPISODES/3\n",
        "    pi_rate_avg += float(pi_successes)/MAX_EPISODES/3\n",
        "\n",
        "    vi_step_avg += avg_vi_steps/3\n",
        "    pi_step_avg += avg_pi_steps/3\n",
        "\n",
        "    vi_time_avg += vi_avg/MAX_EPISODES/3\n",
        "    pi_time_avg += pi_avg/MAX_EPISODES/3\n",
        "\n",
        "    vi_find_optimal_avg += vi_time/3\n",
        "    pi_find_optimal_avg += pi_time/3\n",
        "\n",
        "statistics.append(['Taxi-v3', vi_iter_avg, pi_iter_avg, vi_rate_avg, pi_rate_avg, vi_step_avg, pi_step_avg, vi_time_avg, pi_time_avg, vi_find_optimal_avg, pi_find_optimal_avg])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg1Rg8XmyjO_",
        "outputId": "da5cfd5e-6a53-4111-a9d4-97aa5260ebf2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter  1\n",
            "Converged at 116-th iteration.\n",
            "Number of successes: 10000/10000\n",
            "Average number of steps: 13.0825\n",
            "Converged at 16-th iteration.\n",
            "Number of successes: 10000/10000\n",
            "Average number of steps: 13.0238\n",
            "\n",
            "Number of successes of Value Iteration in Taxi-v3 : 10000/10000,  Time find the optimal policy : 6.195146322250366s\n",
            "Number of successes of Policy Iteration in Taxi-v3 : 10000/10000, Time find the optimal policy : 15.757557392120361s\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Iter  2\n",
            "Converged at 116-th iteration.\n",
            "Number of successes: 10000/10000\n",
            "Average number of steps: 13.0423\n",
            "Converged at 16-th iteration.\n",
            "Number of successes: 10000/10000\n",
            "Average number of steps: 13.0717\n",
            "\n",
            "Number of successes of Value Iteration in Taxi-v3 : 10000/10000,  Time find the optimal policy : 5.707596778869629s\n",
            "Number of successes of Policy Iteration in Taxi-v3 : 10000/10000, Time find the optimal policy : 15.352566957473755s\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Iter  3\n",
            "Converged at 116-th iteration.\n",
            "Number of successes: 10000/10000\n",
            "Average number of steps: 13.1069\n",
            "Converged at 16-th iteration.\n",
            "Number of successes: 10000/10000\n",
            "Average number of steps: 13.0455\n",
            "\n",
            "Number of successes of Value Iteration in Taxi-v3 : 10000/10000,  Time find the optimal policy : 6.861530780792236s\n",
            "Number of successes of Policy Iteration in Taxi-v3 : 10000/10000, Time find the optimal policy : 15.29226303100586s\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparision"
      ],
      "metadata": {
        "id": "2tQPnzLU--uX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(statistics, columns=['Environment', 'VI Iteration', 'PI Iteration', 'VI Success Rate', 'PI Success Rate', 'Average VI Steps', 'Average PI Steps', 'VI Time', 'PI Time', 'Avg VI Find Optimal Time', 'Avg PI Find Optimal Time'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "RDAMili5_GC6",
        "outputId": "6d7f1d83-008e-4eed-c1fb-0ea9d636aa7b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Environment  VI Iteration  PI Iteration  VI Success Rate  \\\n",
              "0     FrozenLake-v1          79.0           5.0         0.781367   \n",
              "1  FrozenLake8x8-v1         117.0           9.0         0.751167   \n",
              "2           Taxi-v3         116.0          16.0         1.000000   \n",
              "\n",
              "   PI Success Rate  Average VI Steps  Average PI Steps   VI Time   PI Time  \\\n",
              "0           0.7795         43.596873         43.443798  0.000863  0.000848   \n",
              "1           0.7492         74.516174         74.942522  0.001428  0.001445   \n",
              "2           1.0000         13.077233         13.047000  0.000480  0.000411   \n",
              "\n",
              "   Avg VI Find Optimal Time  Avg PI Find Optimal Time  \n",
              "0                  0.099310                  0.117507  \n",
              "1                  0.743186                  1.081016  \n",
              "2                  6.254758                 15.467462  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbf96519-f95b-456c-83ff-45095396d632\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Environment</th>\n",
              "      <th>VI Iteration</th>\n",
              "      <th>PI Iteration</th>\n",
              "      <th>VI Success Rate</th>\n",
              "      <th>PI Success Rate</th>\n",
              "      <th>Average VI Steps</th>\n",
              "      <th>Average PI Steps</th>\n",
              "      <th>VI Time</th>\n",
              "      <th>PI Time</th>\n",
              "      <th>Avg VI Find Optimal Time</th>\n",
              "      <th>Avg PI Find Optimal Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FrozenLake-v1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.781367</td>\n",
              "      <td>0.7795</td>\n",
              "      <td>43.596873</td>\n",
              "      <td>43.443798</td>\n",
              "      <td>0.000863</td>\n",
              "      <td>0.000848</td>\n",
              "      <td>0.099310</td>\n",
              "      <td>0.117507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FrozenLake8x8-v1</td>\n",
              "      <td>117.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.751167</td>\n",
              "      <td>0.7492</td>\n",
              "      <td>74.516174</td>\n",
              "      <td>74.942522</td>\n",
              "      <td>0.001428</td>\n",
              "      <td>0.001445</td>\n",
              "      <td>0.743186</td>\n",
              "      <td>1.081016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Taxi-v3</td>\n",
              "      <td>116.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>13.077233</td>\n",
              "      <td>13.047000</td>\n",
              "      <td>0.000480</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>6.254758</td>\n",
              "      <td>15.467462</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbf96519-f95b-456c-83ff-45095396d632')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dbf96519-f95b-456c-83ff-45095396d632 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dbf96519-f95b-456c-83ff-45095396d632');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f8cc2795-1676-496f-a85c-cd09fb4cb01e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f8cc2795-1676-496f-a85c-cd09fb4cb01e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f8cc2795-1676-496f-a85c-cd09fb4cb01e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Environment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"FrozenLake-v1\",\n          \"FrozenLake8x8-v1\",\n          \"Taxi-v3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VI Iteration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.656407827707714,\n        \"min\": 79.0,\n        \"max\": 117.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          79.0,\n          117.0,\n          116.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PI Iteration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.5677643628300215,\n        \"min\": 5.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5.0,\n          9.0,\n          16.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VI Success Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1357881942721962,\n        \"min\": 0.7511666666666666,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7813666666666668,\n          0.7511666666666666,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PI Success Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1368934987499407,\n        \"min\": 0.7492,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7794999999999999,\n          0.7492,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average VI Steps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.71968705439672,\n        \"min\": 13.077233333333332,\n        \"max\": 74.51617414477892,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          43.59687347114696,\n          74.51617414477892,\n          13.077233333333332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average PI Steps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.949395556886618,\n        \"min\": 13.047,\n        \"max\": 74.94252159979621,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          43.4437976189412,\n          74.94252159979621,\n          13.047\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VI Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0004767809704835715,\n        \"min\": 0.0004798243681589763,\n        \"max\": 0.0014276632070541382,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0008634031375249227,\n          0.0014276632070541382,\n          0.0004798243681589763\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PI Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0005188433596485109,\n        \"min\": 0.00041109692255655926,\n        \"max\": 0.0014446535507837933,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0008477764368057252,\n          0.0014446535507837933,\n          0.00041109692255655926\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg VI Find Optimal Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.3833302517764503,\n        \"min\": 0.09931015968322754,\n        \"max\": 6.254757960637411,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.09931015968322754,\n          0.7431857585906982,\n          6.254757960637411\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg PI Find Optimal Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.597667790887433,\n        \"min\": 0.11750658353169759,\n        \"max\": 15.46746246019999,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.11750658353169759,\n          1.0810155868530273,\n          15.46746246019999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the experiment by running the code, here are some general observations:\n",
        "\n",
        "* **Number of iterations to converge**: The Policy\n",
        "Iteration (PI) algorithm converges faster than the Value Iteration (VI) algorithm across all environments. This is reflected in the number of iterations needed for the algorithm to converge.\n",
        "* **Success rate**: Both the VI and PI algorithms have a similar success rate across all environments. Notably, both algorithms achieve an absolute success rate (100%) on the Taxi-v3 environment.\n",
        "* **Average number of steps**: The average number of steps needed to complete an episode is very similar between VI and PI across all environments. This indicates that both algorithms are learning effective strategies.\n",
        "* **Average time**: The average time to complete an episode is also very similar between VI and PI.\n",
        "* **Average time find optimal policy**:  The average time to find the optimal policy is higher for PI than for VI in all environments."
      ],
      "metadata": {
        "id": "p75XrB4DBVqF"
      }
    }
  ]
}